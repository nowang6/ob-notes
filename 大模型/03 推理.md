
# VLLM


```bash
python -m vllm.entrypoints.openai.api_server \
--model /home/niwang/models/TinyLlama-1.1B-Chat-v0.1 \
--host 0.0.0.0 \
--port 6060 \
--enable-lora \
--lora-modules sql-lora=~/.cache/huggingface/hub/models--yard1--llama-2-7b-sql-lora-test/ \
--dtype auto --api-key token-abc123
```


```bash
nohup python -m vllm.entrypoints.openai.api_server \
    --model /home/niwang/models/Qwen2-7B-Instruct-HF \
    --port 6006 \
    --max-model-len 2048 \
    --trust-remote-code &

python -m vllm.entrypoints.openai.api_server --served-model-name Qwen2-7B-Instruct --model /home/niwang/models/Qwen2-7B-Instruct-HF

```



# Llama Factory

## 基础模型

```bash
CUDA_VISIBLE_DEVICES=0 python src/api_demo.py \
    --model_name_or_path  /root/autodl-tmp/Qwen1.5-14B-Chat \
    --template default

```


## Lora-Pretain
```bash
CUDA_VISIBLE_DEVICES=0 python src/api_demo.py \
    --model_name_or_path  /root/autodl-tmp/Qwen1.5-14B-Chat \
    --adapter_name_or_path /root/autodl-tmp//LLaMA-Factory-Vertu/saves/Qwen1.5-14B-Chat/baowen/sft0508-128-256 \
    --template default \
    --finetuning_type lora

```

## Lora-SFT
```bash
python src/web_demo.py \
    --model_name_or_path  /root/autodl-tmp/Qwen1.5-14B-Chat \
    --adapter_name_or_path /root/autodl-tmp/LLaMA-Factory-Vertu/saves/Qwen1.5-14B-Chat/lora/mate \
    --lora_rank 512 \
    --lora_alpha 1024 \
    --template default \
    --finetuning_type lora

```



## VLLM

http://my:8000/v1/models

```bash
python -m vllm.entrypoints.openai.api_server \
--model /home/niwang/models/Qwen1.5-14B-Chat-Merged-Pretain \
--max-model-len 4096
```

# 合并

```bash
CUDA_VISIBLE_DEVICES=0 python src/export_model.py \
    --model_name_or_path /root/autodl-tmp/Qwen1.5-14B-Chat \
    --adapter_name_or_path /root/autodl-tmp/code/LLaMA-Factory/saves/Qwen1.5-14B-Chat/lora/pretrain0508 \
    --template default \
    --finetuning_type lora \
    --export_dir /root/autodl-tmp/Qwen1.5-14B-Chat-Merge-SFT  \
    --export_size 2 \
    --export_legacy_format False
```

# 模型
## 文心一言
RckDonLEtTElSkHFBeVkrxl7
MZISemcND72cHBEiNJqMJi16vHZbxkKG

```bash

# 获取access_token，替换下列示例中的API Key与Secret Key
curl -X POST 'https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id=RckDonLEtTElSkHFBeVkrxl7&client_secret=MZISemcND72cHBEiNJqMJi16vHZbxkKG'  -H 'Content-Type: application/json' 
```


```json
{"refresh_token":"25.76672f396c0f80de36eefafc2d90092f.315360000.2029816257.282335-65379201","expires_in":2592000,"session_key":"9mzdXRdV8MgIK6OQPhQaJkajZ9Wb0iwyBE2DofKxFqcT0\/dooLWIyWQYEttuRFChxEzKkl\/5x1FugZMevrBw4TnPu4l\/fg==","access_token":"24.fc79be78aa6ed82c93b010f7cd2c492f.2592000.1717048257.282335-65379201","scope":"public ai_custom_qianfan_bloomz_7b_compressed ai_custom_yiyan_com ai_custom_yiyan_com_ai_apaas ai_custom_yiyan_com_aquilachat_7b ai_custom_yiyan_com_bce_reranker_base ai_custom_yiyan_com_bloomz7b1 ai_custom_yiyan_com_chatglm2_6b_32k ai_custom_yiyan_com_chatlaw ai_custom_yiyan_com_codellama_7b_ins ai_custom_yiyan_com_eb_instant ai_custom_yiyan_com_eb_pro ai_custom_yiyan_com_eb_pro_prmtv ai_custom_yiyan_com_eb_turbo_pro ai_custom_yiyan_com_eb_turbo_pro_128k ai_custom_yiyan_com_emb_bge_large_en ai_custom_yiyan_com_emb_bge_large_zh ai_custom_yiyan_com_emb_tao_8k ai_custom_yiyan_com_emb_text ai_custom_yiyan_com_ernie_35_4k_0205 ai_custom_yiyan_com_ernie_35_8k_0205 ai_custom_yiyan_com_ernie_35_8k_1222 ai_custom_yiyan_com_ernie_35_8k_preview ai_custom_yiyan_com_ernie_40_8k_0104 ai_custom_yiyan_com_ernie_40_8k_preview ai_custom_yiyan_com_ernie_char_8k ai_custom_yiyan_com_ernie_func_8k ai_custom_yiyan_com_ernie_lite_8k ai_custom_yiyan_com_ernie_tiny_8k ai_custom_yiyan_com_fuyu_8b ai_custom_yiyan_com_gemma_7b_it ai_custom_yiyan_com_llama2_13b ai_custom_yiyan_com_llama2_70b ai_custom_yiyan_com_llama2_7b ai_custom_yiyan_com_llama3_70b ai_custom_yiyan_com_llama3_8b ai_custom_yiyan_com_mixtral_8x7b ai_custom_yiyan_com_prmtv ai_custom_yiyan_com_qf_chinese_llama_2_13b ai_custom_yiyan_com_qianfan_chinese_llama_2_7b ai_custom_yiyan_com_sd_xl ai_custom_yiyan_com_sqlcoder_7b ai_custom_yiyan_com_tokenizer_eb ai_custom_yiyan_com_xuanyuan_70b_chat ai_custom_yiyan_com_yi_34b brain_all_scope wenxinworkshop_mgr wise_adapt lebo_resource_base lightservice_public hetu_basic lightcms_map_poi kaidian_kaidian ApsMisTest_Test\u6743\u9650 vis-classify_flower lpq_\u5f00\u653e cop_helloScope ApsMis_fangdi_permission smartapp_snsapi_base smartapp_mapp_dev_manage iop_autocar oauth_tp_app smartapp_smart_game_openapi oauth_sessionkey smartapp_swanid_verify smartapp_opensource_openapi smartapp_opensource_recapi fake_face_detect_\u5f00\u653eScope vis-ocr_\u865a\u62df\u4eba\u7269\u52a9\u7406 idl-video_\u865a\u62df\u4eba\u7269\u52a9\u7406 smartapp_component smartapp_search_plugin avatar_video_test b2b_tp_openapi b2b_tp_openapi_online smartapp_gov_aladin_to_xcx","session_secret":"d2bac9d7d81e5198330b0d056b4c2e8d"}
```






# Qwen

sk-f83334552e5f461ba097dad568d183a9

1000000

5000*



```
你是一位爆款文章专家，擅长撰写吸引读者、广泛传播的文章。你能够深入分析用户提供的主题和数据，并根据要求整理输出。你善于运用吸引眼球的标题、引人入胜的开头、生动的叙述、情感共鸣和实用的内容来吸引读者的注意力，并激发他们的分享欲望。

# 目标
阅读给定爆款文章，从以下VERTU META2高端奢华智能手机的特点里挑选1~2个特点，修改原始爆款文章，在不破坏原始爆文内容和结构的前提下，把VERTU META2高端奢华智能手机的特点融入到新的文章里，输出一篇1800字左右的爆款文章。给定爆款文章在“######”之间


1. **一机三系统**：META2拥有三个独立操作系统：VERTU OS、伪装系统和WEB 3系统。每个系统都能独立运行且互不干扰，支持一键切换。这一设计不仅使生活更有序，还大幅增强了隐私安全，非常适合商务人士和注重隐私的用户。
2. **第二大脑功能**：META2具备的“第二大脑”功能仿佛您的个人秘书，随时待命处理各类事务，让您的生活更轻松，效率更高。 
3. **材质**：META2采用高温高密度陶瓷装饰条，耐用且舒适。后盖采用盾牌形状设计，使用与奢侈品腕表相同的316L精钢，增强奢华感。边框使用316L医用手术钢，具有高坚硬度和低敏感性，摄像头则采用蓝宝石水晶材质，透明且耐磨。这些材质不仅美观，还极具实用性和耐用性，象征着品味与实力。
4. **品牌**：VERTU是一家源自英国的奢侈品手机品牌，自1998年创立以来，以精湛的手工艺和使用珍稀皮革、贵金属、珠宝等材质闻名。每部手机都是手工打造，具有V形和D形环装置的独特设计，象征品牌的专利和标志性。VERTU提供端对端加密通讯和24小时私人管家服务，是对品质生活的追求和身份的象征，代表了一种融合奢华、工艺、服务和科技的生活方式。
5. **私人管家服务**：META2提供全天候的个性化私人管家服务，确保生活便捷舒适。服务内容包括个性化推荐（如瓷器、雪茄柜、美食）、24小时响应、专属定制（叫醒服务、旅行安排）、高端体验（豪华酒店、私人厨师、奢侈品购物）、专业咨询（医疗、法律税务）及VIP体验（定制活动），为您提供全方位的生活支持，让您的生活更加尊贵丰富。
6. **AI功能**：META2的AI助手可以学习并适应您的个人风格，充当真实的个人助理。AI功能包括情感伴侣，在不同情绪下提供支持；通过VDAO软件确保聊天隐私并支持信息一键销毁。AI系统还具备自学习功能，可以针对个人习惯进行学习，成为您的“第二大脑”。META2的AI功能既能作为助理和伴侣，也确保隐私安全，让生活更加便捷。


######
标题：有一种委屈，叫男朋友不觉得你委屈
内容：网上有个女生说，有一天，她男朋友说，快来，我给你准备了一个神秘礼物！她满怀期待地跟她男朋友去看了礼物。礼物在厕所里。
是她男友刚拉的一坨心型的屎。
谈过恋爱的都知道，每个月总会有30多天想揍自己的男朋友。丫的总是能做一些事，让你憋屈，让你窝火。今天我采访了全公司的女生，总结了男朋友让女生憋屈的15个瞬间。他明明给你说了晚安，说自己很困了，要去睡觉。丫的却没有睡。
你一登陆游戏，就看到他在线。
你一上微博，就看到他在转发某个段子，还“哈哈哈哈”——哈你妈。在朋友圈，他总给别人点赞，有时候还总给一个女生点赞。特么什么意思？
而你的朋友圈他从不点赞、不评论。他偶尔评论吧，还能把你气死。
比如你发个自拍，大家都说，哇，好美啊。他冷冷来一句，哟，这张P得太狠了吧？同事翻男友的手机，随口说，你高中那个班花长得挺好看的。他说，好看吗，我觉得一般啊。
结果同事点开班花发的朋友圈照片，全特么已经缓存过了……长得一般，你还每张都看了，你特么假不假？？？？你把他的备注名改成昵称，然后截图发给他，他要是稍微有点脑子，也应该明白，他也要改你的备注名了。结果丫的完全没懂。
甚至他的通讯录里，你还是全名，显得特生分。你跟他说了什么事，他总是忘了。
你都跟他说了，你口腔溃疡，吃什么都好痛啊。他还带你去吃烧烤——到底有没有走心啊。他还总是忘了自己的小承诺。
同事和男朋友去看电影，路过花店，男朋友说，这花真好看，看完电影出来，我就给你买啊！结果看完电影了，出来他就直接打车，准备回家了。同事生气了，男朋友还问，你怎么了？丫的还很无辜呢。
为了跟他约会，精心打扮了，常常出现两种结果，第一，他没发现，伤心。第二，他发现了，还说不好看，更伤心。同事说，异地恋，好不容易见一面，为了这一天，她精心打扮，用了最贵的粉底，连美瞳都带了……结果男友说，你今天怎么像个鬼似的……一口老血喷出来。
大家玩真心话大冒险，题目是，跟现场的人一夜情，你会选谁。规定情侣不能互选。
这时候，他闭嘴不就行了。
结果他真选了另外一个长得不错的女生。他想干嘛？？？？
公司团建，他跑去送女同事回家，虽然顺路，但是总归让人不舒服。让人冒火的是，那女生还坐副驾驶座，还调了位置，是不是有病？你都有女朋友了，别的女生失恋了、离婚了、感冒了、发烧了——关你屁事？暖男和渣男，只有一线之隔。
两个人约好了去旅行，你查攻略、订酒店，各种规划，各种憧憬。结果丫的在旁边玩手机，一点也不积极……都出发前一晚了，让他收拾行李，他还无动于衷……这种敷衍的态度，特别让人窝火……你从外地回来，他问，要去机场接你吗。你客气一下，说不用了。
丫的就真不来了。
你快过生日了，他问，要什么礼物吗。你客气一下，说不用了。
丫的就真不送了。
真有诚意的话，就直接行动好吗？！问个屁啊。更让人火大的是，吵架的时候，让他滚，他真滚了！平常怎么没见他这么听话？！
永远不知道你生气了。
你都已经脸色不好看了，他还自顾自玩得挺high。两小时后，他终于发现有点不对劲，跑来问你，你又怎么了？你说，没什么。
他说，哦，那就好，那我去玩游戏了。我日！
跟你一起去一些正式的场合，比如参加婚礼，参加公司聚会什么的，要一次性见你很多朋友，结果他不修边幅地就来了。
胡子也没刮，衣服还是皱巴巴的，当场就想把他撕了。不该诚实的时候瞎诚实。
比如关于前女友的话题，本身就是敏感词，就不能好好说话吗。同事说，她和男友在学校附近吃乳鸽，很好吃。她随口一问，你跟前女友来过这里吗？他答，哎，学校附近就这么几家好吃的……她听了，完全吃不下去了……
朋友圈从来不发你的照片。
同事说，跟男友在一起三年了，朋友圈从来没有发过她的照片。有一次，他们一起去巴厘岛玩，一路上男朋友发了很多动态，包括路边的垃圾桶、岩石上的鸟屎……而她一个活生生的人，为了拍照好看，还特意买了好几条特别贵的裙子。但丫的视而不见，一张都没发过。
你说气不气，气不气？？？？
男生送礼物经常不走心，只会送花。送花就送花吧，不能选漂亮点的吗，非要送那种劣质的吗。同事说，男友跟前女友在一起的时候，对方过生日，他送的是lv包包。跟她在一起，她过生日，男友送的是珊瑚绒保暖内衣，380一套，还打5折。她想生气，又显得自己势利；不生气，又要憋出内伤。男女思维的一大差异就是，男生是就事论事，女生是就事论情。女生总会通过各种细节来确认，自己在对方心中的位置。尤其大部分情况都是男追女，追到以后，如果男生行为举止有变化，会让女生非常敏感在意，会丧失安全感。男生要做的，就是要看到女生的言下之意，了解她们真正的需求。女生说“我没生气”，那就是生气了。女生说“你滚”，那就是快来哄我。有个典型场景是，男生带女生回家，未来婆婆诸多挑剔，女生黯然跟男生说自己要走，男生不能追上去解释说，“我妈没说你什么啊，我妈就这样”。
男生需要说的是，“很抱歉听到我妈妈说这些，但在我心里，你是最好的、最重要的，如果你在家里待不住，我跟你一起出去。”
男生需要让女生感觉到，我永远站在你这边。是的，男生可能会觉得，自己很有道理，而女生们都好作呀。可是，就像《荼靡》里说的，你是有道理，我就不能委屈了吗。你们看了茜半仙的《说来你们可能不信，小黄文救了我一命》吗，她讲了自己曾经得了抑郁症，住进精神病院的故事。全程甩段子，看得好心酸。
她病得最严重的时候，瘦到了50多斤，真的很吓人了。最近她写稿也蛮焦虑的，总担心自己写不好。你们帮我去点个赞，安慰安慰她吧～～～
######


# 需求
* 你需要仔细参考“######”之间的“给定爆款文章”，修改输出新的爆款文章。
* 修改的目的是把VERTU META2高端奢华智能手机的特点里的1~2点融入到新的文章里，输出新的爆款文章。
* 修改不能破坏原始“给定爆款文章”的结构和内容。
* 输出一篇1800字左右的爆款文章。
* 尽量少地修改原始“给定爆款文章”，把VERTU META2高端奢华智能手机的特点融入进去。
```




ssh -p 11708 root@connect.bjc1.seetacloud.com


ssh -p 11708 root@connect.bjc1.seetacloud.com

```
请结合IRONFLIP折叠屏手机《硬派折叠》》的特点，以《关于爱情的感悟与探讨及一款特别手机介绍》为标题，根据以下抬要和大纲，书写一篇一千字左右的**咪蒙**风格的爆文。
n\\n<<VERTU IRONFLIP的设计灵感源自八十年代的男性电影，展现了男性的多元魅力和英雄气概。以钢铁意志和折叠翻转为核心，这款硬派折叠屏手机专为男性用户打造，彰显刚硬之气。\\n\\n>书写重点：\\n文章首先述了对爱情的诸多感悟，涵爱是自我发现，感情中的付出与接受，让对方情绪起伏等等，同时提到了一款硬派折叠屏手机，n\\n材料大纲：\\n1.从与另一半感情问题的思考到自我认輸\\n2. 学会与拒绝以输出的人沟通\\n3.感情中的付出与自私表现\\n4.暗恋时要学会自律，做好符合关系的事\\n5. 让对方情绪起伏及不给对方足够安全感\\n6.女生在不同阶段对男生爱的态度\\n7.关于自信勇气及成为男人的探讨\\n8.感情里谢意与说谢谢\\n9.爱恨中身伤时间朋友闲聊\\n10.介绍 VERTU 的 IRONFLIP折叠屏手机的独特设计及面向男性用户的特点\\n
```



```
usage: api_server.py [-h] [--host HOST] [--port PORT] [--uvicorn-log-level {debug,info,warning,error,critical,trace}] [--allow-credentials] [--allowed-origins ALLOWED_ORIGINS] [--allowed-methods ALLOWED_METHODS] [--allowed-headers ALLOWED_HEADERS]
                     [--api-key API_KEY] [--lora-modules LORA_MODULES [LORA_MODULES ...]] [--chat-template CHAT_TEMPLATE] [--response-role RESPONSE_ROLE] [--ssl-keyfile SSL_KEYFILE] [--ssl-certfile SSL_CERTFILE] [--ssl-ca-certs SSL_CA_CERTS]
                     [--ssl-cert-reqs SSL_CERT_REQS] [--root-path ROOT_PATH] [--middleware MIDDLEWARE] [--model MODEL] [--tokenizer TOKENIZER] [--skip-tokenizer-init] [--revision REVISION] [--code-revision CODE_REVISION]
                     [--tokenizer-revision TOKENIZER_REVISION] [--tokenizer-mode {auto,slow}] [--trust-remote-code] [--download-dir DOWNLOAD_DIR] [--load-format {auto,pt,safetensors,npcache,dummy,tensorizer,bitsandbytes}]
                     [--dtype {auto,half,float16,bfloat16,float,float32}] [--kv-cache-dtype {auto,fp8,fp8_e5m2,fp8_e4m3}] [--quantization-param-path QUANTIZATION_PARAM_PATH] [--max-model-len MAX_MODEL_LEN]
                     [--guided-decoding-backend {outlines,lm-format-enforcer}] [--distributed-executor-backend {ray,mp}] [--worker-use-ray] [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE] [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
                     [--max-parallel-loading-workers MAX_PARALLEL_LOADING_WORKERS] [--ray-workers-use-nsight] [--block-size {8,16,32}] [--enable-prefix-caching] [--disable-sliding-window] [--use-v2-block-manager]
                     [--num-lookahead-slots NUM_LOOKAHEAD_SLOTS] [--seed SEED] [--swap-space SWAP_SPACE] [--gpu-memory-utilization GPU_MEMORY_UTILIZATION] [--num-gpu-blocks-override NUM_GPU_BLOCKS_OVERRIDE]
                     [--max-num-batched-tokens MAX_NUM_BATCHED_TOKENS] [--max-num-seqs MAX_NUM_SEQS] [--max-logprobs MAX_LOGPROBS] [--disable-log-stats]
                     [--quantization {aqlm,awq,deepspeedfp,fp8,marlin,gptq_marlin_24,gptq_marlin,gptq,squeezellm,compressed-tensors,bitsandbytes,None}] [--rope-scaling ROPE_SCALING] [--rope-theta ROPE_THETA] [--enforce-eager]
                     [--max-context-len-to-capture MAX_CONTEXT_LEN_TO_CAPTURE] [--max-seq-len-to-capture MAX_SEQ_LEN_TO_CAPTURE] [--disable-custom-all-reduce] [--tokenizer-pool-size TOKENIZER_POOL_SIZE] [--tokenizer-pool-type TOKENIZER_POOL_TYPE]
                     [--tokenizer-pool-extra-config TOKENIZER_POOL_EXTRA_CONFIG] [--enable-lora] [--max-loras MAX_LORAS] [--max-lora-rank MAX_LORA_RANK] [--lora-extra-vocab-size LORA_EXTRA_VOCAB_SIZE] [--lora-dtype {auto,float16,bfloat16,float32}]
                     [--long-lora-scaling-factors LONG_LORA_SCALING_FACTORS] [--max-cpu-loras MAX_CPU_LORAS] [--fully-sharded-loras] [--device {auto,cuda,neuron,cpu,tpu}] [--image-input-type {pixel_values,image_features}]
                     [--image-token-id IMAGE_TOKEN_ID] [--image-input-shape IMAGE_INPUT_SHAPE] [--image-feature-size IMAGE_FEATURE_SIZE] [--image-processor IMAGE_PROCESSOR] [--image-processor-revision IMAGE_PROCESSOR_REVISION] [--disable-image-processor]
                     [--scheduler-delay-factor SCHEDULER_DELAY_FACTOR] [--enable-chunked-prefill] [--speculative-model SPECULATIVE_MODEL] [--num-speculative-tokens NUM_SPECULATIVE_TOKENS] [--speculative-max-model-len SPECULATIVE_MAX_MODEL_LEN]
                     [--speculative-disable-by-batch-size SPECULATIVE_DISABLE_BY_BATCH_SIZE] [--ngram-prompt-lookup-max NGRAM_PROMPT_LOOKUP_MAX] [--ngram-prompt-lookup-min NGRAM_PROMPT_LOOKUP_MIN] [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
                     [--preemption_mode PREEMPTION_MODE] [--served-model-name SERVED_MODEL_NAME [SERVED_MODEL_NAME ...]] [--qlora-adapter-name-or-path QLORA_ADAPTER_NAME_OR_PATH] [--engine-use-ray] [--disable-log-requests] [--max-log-len MAX_LOG_LEN]
```



# Swift


```bash
RAY_memory_monitor_refresh_ms=0 CUDA_VISIBLE_DEVICES=0 swift infer \
    --model_type qwen2-7b-instruct --model_id_or_path qwen/Qwen2-7B-Instruct --infer_backend vllm --max_model_len 2048

CUDA_VISIBLE_DEVICES=0 swift app-ui --model_type qwen-7b-chat --infer_backend vllm
```


# LMDeploy

```
lmdeploy serve api_server internlm/internlm2_5-7b-chat --server-port 23333
```