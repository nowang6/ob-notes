
# 推理

## VLLM

```
python -m vllm.entrypoints.openai.api_server --model /home/niwang/models/Qwen1.5-7B-Chat --max-model-len 8192

```

# LMDeploy

https://github.com/InternLM/lmdeploy/blob/main/docs/zh_cn/llm/api_server.md


```bash
nohup lmdeploy serve api_server \
/home/niwang/models/Qwen2-72B-Instruct-AWQ \
--server-port 23333 &
```


```python
from openai import OpenAI
from openai.types.completion_choice import CompletionChoice

model = "glm4-chat"

openai_api_key = "EMPTY" 
openai_api_base = "http://my:23333/v1"

promopt = "Say this is a test"

client = OpenAI(api_key=openai_api_key, base_url=openai_api_base)


stream = client.chat.completions.create(model=model, 
										messages=[{"role": "user", "content": promopt}], stream=True
)

print("Completion results:")
for chunk in stream: 
	print(chunk.choices[0].delta.content or "", end="")
```


# 量化

模型压缩技术
- 量化
- 稀疏
- 低秩分解
  - SVD分解
- NAS 神经网络结构搜索 模型设计阶段
- 知识蒸馏


![[Pasted image 20240404065001.png]]

# 硬件

![[Pasted image 20240404101727.png]]
Adreno GPU (ATI技术)
Hexagon NPU (AI专用处理器)

# 工具

## dipoorlet - 商汤
内部工具
https://github.com/ModelTC/Dipoorlet

## Openppl PPQ
面向开源
https://github.com/openppl-public/ppq

## MLC.AI.  Machine Learning Compilation





# 量化技术
对称量化，非对称量化
均匀量化，非均匀量化
静态量化，动态量化


# 数据校准
MinMax
KL Divergence （TensorRT使用）
MSE
Histogram



[MQBench: Towards Reproducible and Deployable Model Quantization Benchmark 论文学习-CSDN博客](https://blog.csdn.net/qq_31993233/article/details/123893593)

# 离线和在线量化
Post Training Quantization PTQ 离线量化
Quantization Aware Training 在线量化
![[Pasted image 20240406184740.png]]

# 开发板
qcm6125

[Hexagon SDK - Tools - Qualcomm Developer Network](https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools)

为了将AI“装进”手机：通过NPU和异构计算开启终端侧生成式AI-高通白皮书
[[通过 NPU 和异构计算开启终端侧生成式 AI.pdf]]


DFQ是什么？


# Xinference



```bash

pip install "xinference[all]"

XINFERENCE_HOME=/root/autodl-tmp xinference-local --host 0.0.0.0 --port 9997

#查询qwen-chat模型相关的参数组合参数
xinference engine --model-name bge-m3




#查询所有注册了的模型, 默认为llm
xinference registrations

xinference registrations -t embedding



xinference launch --model-engine vLLM --model-name glm4-chat --size-in-billions 9 --model-format pytorch


xinference launch --model-name bge-base-zh-v1.5 --model-type embedding

```


```bash
xinference launch --model_path /home/niwang/models/Qwen2-72B-Instruct-AWQ --model-engine vllm -n qwen2-chat


xinference launch --model-engine vllm --model-name qwen-chat --size-in-billions 72 --model-format gptq --quantization Int4

xinference launch --model-engine vllm --model-name qwen-chat --size-in-billions 7 --model-format pytorch --quantization Int4


.jpg, .jpeg, .png, .gif, .webp
```

